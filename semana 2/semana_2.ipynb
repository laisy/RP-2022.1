{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "names_columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"clas\"]\n",
    "df = pd.read_csv(\"iris.data\", names=names_columns)\n",
    "df.clas.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTÃO 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        25\n",
      "Iris-versicolor       0.85      0.92      0.88        25\n",
      " Iris-virginica       0.91      0.84      0.87        25\n",
      "\n",
      "       accuracy                           0.92        75\n",
      "      macro avg       0.92      0.92      0.92        75\n",
      "   weighted avg       0.92      0.92      0.92        75\n",
      "\n",
      "[[25  0  0]\n",
      " [ 0 23  2]\n",
      " [ 0  4 21]]\n",
      "Porcentagem acertos:  92.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laisy/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ler arquivo e Pegar colunas\n",
    "names_columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"Class\"]\n",
    "df = pd.read_csv(\"iris.data\", names=names_columns)\n",
    "\n",
    "# Especie de PRINT pra vê o arquivo\n",
    "df.Class.unique()\n",
    "\n",
    "# Separo as classes pelos tipos de flores\n",
    "setosa = df[(df['Class'] == 'Iris-setosa')]\n",
    "versicolor = df[(df['Class'] == 'Iris-versicolor')]\n",
    "virginica = df[(df['Class'] == 'Iris-virginica')]\n",
    "\n",
    "\n",
    "# train_test_split: Dividir arrays ou matrizes em subconjuntos aleatórios de treino e teste\n",
    "# test_size=0.5 (tamanho da divisão, ex: 0.5 representa a metade)\n",
    "\n",
    "# SETOSA\n",
    "setosa_x = setosa[setosa.columns[:4:]]\n",
    "setosa_y = setosa[setosa.columns[-1::]]\n",
    "\n",
    "setosa_x_treino, setosa_x_teste, setosa_y_treino, setosa_y_teste = train_test_split (setosa_x, setosa_y, test_size=0.5)\n",
    "\n",
    "# VERSICOLO\n",
    "versicolor_x = versicolor[versicolor.columns[:4:]]\n",
    "versicolor_y = versicolor[versicolor.columns[-1::]]\n",
    "\n",
    "versicolor_x_treino, versicolor_x_teste, versicolor_y_treino, versicolor_y_teste = train_test_split (versicolor_x,versicolor_y,test_size=0.5)\n",
    "\n",
    "# VIRGINICA\n",
    "virginica_x = virginica[virginica.columns[:4:]]\n",
    "virginica_y = virginica[virginica.columns[-1::]]\n",
    "\n",
    "virginica_x_treino, virginica_x_teste, virginica_y_treino, virginica_y_teste = train_test_split (virginica_x, virginica_y,test_size=0.5)\n",
    "\n",
    "\n",
    "# Junta os conjuntos de treino e teste pelos grupos\n",
    "# TREINO\n",
    "x_treino = pd.concat([setosa_x_treino, versicolor_x_treino, virginica_x_treino])\n",
    "y_treino = pd.concat([setosa_y_treino, versicolor_y_treino, virginica_y_treino])\n",
    "\n",
    "# TESTE\n",
    "x_teste = pd.concat([setosa_x_teste, versicolor_x_teste, virginica_x_teste])\n",
    "y_teste = pd.concat([setosa_y_teste, versicolor_y_teste, virginica_y_teste])\n",
    "\n",
    "# Padroniza os recursos removendo a média e dimensionando para a variação da unidade\n",
    "scaler = StandardScaler()\n",
    "# Calcula a média e o padrão a serem usados para dimensionamento posterior\n",
    "# Ajusta aos dados e, em seguida, transforma-os.\n",
    "scaler.fit(x_treino)\n",
    "x_treino = scaler.transform(x_treino)\n",
    "x_teste = scaler.transform(x_teste)\n",
    "\n",
    "# Classificador que implementa o voto dos k vizinhos mais próximos.\n",
    "classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "classifier.fit(x_treino, y_treino)\n",
    "\n",
    "y_pred = classifier.predict(x_teste)\n",
    "\n",
    "print(classification_report(y_teste, y_pred))\n",
    "print(confusion_matrix(y_teste, y_pred))\n",
    "\n",
    "print(\"Porcentagem acertos: \", str(format(accuracy_score(y_teste, y_pred)*100, '.2f') + \"%\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTÃO 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/laisy/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_51610/3231937612.py\", line 52, in <module>\n",
      "    df.x_teste.iterrows()\n",
      "  File \"/home/laisy/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 5902, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "AttributeError: 'DataFrame' object has no attribute 'x_teste'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/laisy/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2052, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/laisy/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/laisy/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/laisy/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/laisy/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 793, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/home/laisy/.local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 839, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"/home/laisy/.local/lib/python3.8/site-packages/stack_data/core.py\", line 441, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/usr/lib/python3/dist-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"/usr/lib/python3/dist-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def calc_distancia(treino, teste):\n",
    "    # distância euclidiana\n",
    "    distancia = ((treino[0]-teste[0])**2 + (treino[1]-teste[1])**2 + (treino[2]-teste[2])**2 + (treino[3]-teste[3])**2)**0.5\n",
    "    return distancia\n",
    "\n",
    "def array_valores(row):\n",
    "    array = []\n",
    "    array.append(row[\"sepal_length\"])\n",
    "    array.append(row[\"sepal_width\"])\n",
    "    array.append(row[\"petal_length\"])\n",
    "    array.append(row[\"petal_width\"])\n",
    "    return array\n",
    "\n",
    "names_columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"Class\"]\n",
    "df = pd.read_csv(\"iris.data\", names=names_columns)\n",
    "df.Class.unique()\n",
    "\n",
    "setosa = df[(df['Class'] == 'Iris-setosa')]\n",
    "versicolor = df[(df['Class'] == 'Iris-versicolor')]\n",
    "virginica = df[(df['Class'] == 'Iris-virginica')]\n",
    "\n",
    "# SETOSA\n",
    "setosa_treino, setosa_teste = train_test_split(setosa,test_size=0.5)\n",
    "\n",
    "# VERSICOLO\n",
    "versicolor_treino, versicolor_teste = train_test_split(versicolor,test_size=0.5)\n",
    "\n",
    "# VIRGINICA\n",
    "virginica_treino, virginica_teste = train_test_split(virginica,test_size=0.5)\n",
    "\n",
    "# TREINO\n",
    "treino = pd.concat([setosa_treino, versicolor_treino, virginica_treino])\n",
    "x_treino = treino[treino.columns[:4:]]\n",
    "y_treino = treino[treino.columns[-1::]]\n",
    "\n",
    "# TESTE\n",
    "teste = pd.concat([setosa_teste, versicolor_teste, virginica_teste])\n",
    "x_teste = teste[teste.columns[:4:]]\n",
    "y_teste = teste[teste.columns[-1::]]\n",
    "\n",
    "y_pred = y_teste.copy()\n",
    "\n",
    "# para cada iteração do loop externo: terá as informações da instância atual do conjunto de teste, todas as instâncias do conjunto treino serão percorridas, \n",
    "# calculando a distância e substituindo a classe no dataframe de predição caso seja a menor distância\n",
    "\n",
    "# Métodos do Pandas - iterrows: gera um objeto iterador do DataFrame, permitindo iterar cada linha do DataFrame.\n",
    "# Cada iteração produz um objeto de índice e um objeto de linha (um objeto da série Pandas).\n",
    "for k, row1 in x_teste.iterrows():\n",
    "    array_dist_teste = array_valores(row1)\n",
    "    # maior tamanho possivel para ir atualizando\n",
    "    menor_dist = 999999.9\n",
    "    for j, row2 in x_treino.iterrows():\n",
    "        array_dist_treino = array_valores(row2)\n",
    "        distancia = calc_distancia(array_dist_treino, array_dist_teste)\n",
    "        if (distancia < menor_dist):\n",
    "            menor_dist = distancia\n",
    "            y_pred.loc[k, 'Class'] = y_treino.loc[j, 'Class']\n",
    "\n",
    "print(classification_report(y_teste, y_pred))\n",
    "print(confusion_matrix(y_teste, y_pred))\n",
    "print(\"Porcentagem acertos: \", str(format(accuracy_score(y_teste, y_pred)*100, '.2f') + \"%\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 5 - 7-NN com peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      1.00      0.94        30\n",
      "           2       1.00      0.78      0.88        36\n",
      "           3       0.86      1.00      0.92        24\n",
      "\n",
      "    accuracy                           0.91        90\n",
      "   macro avg       0.91      0.93      0.91        90\n",
      "weighted avg       0.92      0.91      0.91        90\n",
      "\n",
      "[[30  0  0]\n",
      " [ 4 28  4]\n",
      " [ 0  0 24]]\n",
      "Porcentagem acertos:  91.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laisy/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "names_columns = ['Class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline']\n",
    "\n",
    "df = pd.read_csv(\"wine.data\", names=names_columns)\n",
    "df.Alcohol.unique()\n",
    "\n",
    "classe_1 = df[(df['Class'] == 1)]\n",
    "classe_2 = df[(df['Class'] == 2)]\n",
    "classe_3 = df[(df['Class'] == 3)]\n",
    "\n",
    "classe_1_treino, classe_1_teste = train_test_split(classe_1,test_size=0.5)\n",
    "classe_2_treino, classe_2_teste = train_test_split(classe_2,test_size=0.5)\n",
    "classe_3_treino, classe_3_teste = train_test_split(classe_3,test_size=0.5)\n",
    "\n",
    "# treino\n",
    "treino = pd.concat([classe_1_treino, classe_2_treino, classe_3_treino])\n",
    "x_treino = treino[treino.columns[1:13:]]\n",
    "y_treino = treino[treino.columns[:1:]]\n",
    "\n",
    "# teste\n",
    "teste = pd.concat([classe_1_teste, classe_2_teste, classe_3_teste])\n",
    "x_teste = teste[teste.columns[1:13:]]\n",
    "y_teste = teste[teste.columns[:1:]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_treino)\n",
    "x_treino = scaler.transform(x_treino)\n",
    "x_teste = scaler.transform(x_teste)\n",
    "\n",
    "# PESO: weights='distance'\n",
    "classificador = KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "classificador.fit(x_treino, y_treino)\n",
    "\n",
    "y_pred = classificador.predict(x_teste)\n",
    "\n",
    "print(classification_report(y_teste, y_pred))\n",
    "print(confusion_matrix(y_teste, y_pred))\n",
    "print(\"Porcentagem acertos: \", str(format(accuracy_score(y_teste, y_pred)*100, '.2f') + \"%\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 5 - 7-NN sem peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.93      0.89        30\n",
      "           2       0.93      0.78      0.85        36\n",
      "           3       0.89      1.00      0.94        24\n",
      "\n",
      "    accuracy                           0.89        90\n",
      "   macro avg       0.89      0.90      0.89        90\n",
      "weighted avg       0.89      0.89      0.89        90\n",
      "\n",
      "[[28  2  0]\n",
      " [ 5 28  3]\n",
      " [ 0  0 24]]\n",
      "Porcentagem acertos:  88.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laisy/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "names_columns = ['Class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline']\n",
    "\n",
    "df = pd.read_csv(\"wine.data\", names=names_columns)\n",
    "df.Alcohol.unique()\n",
    "\n",
    "classe_1 = df[(df['Class'] == 1)]\n",
    "classe_2 = df[(df['Class'] == 2)]\n",
    "classe_3 = df[(df['Class'] == 3)]\n",
    "\n",
    "classe_1_treino, classe_1_teste = train_test_split(classe_1,test_size=0.5)\n",
    "classe_2_treino, classe_2_teste = train_test_split(classe_2,test_size=0.5)\n",
    "classe_3_treino, classe_3_teste = train_test_split(classe_3,test_size=0.5)\n",
    "\n",
    "# treino\n",
    "treino = pd.concat([classe_1_treino, classe_2_treino, classe_3_treino])\n",
    "x_treino = treino[treino.columns[1:13:]]\n",
    "y_treino = treino[treino.columns[:1:]]\n",
    "\n",
    "# teste\n",
    "teste = pd.concat([classe_1_teste, classe_2_teste, classe_3_teste])\n",
    "x_teste = teste[teste.columns[1:13:]]\n",
    "y_teste = teste[teste.columns[:1:]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_treino)\n",
    "x_treino = scaler.transform(x_treino)\n",
    "x_teste = scaler.transform(x_teste)\n",
    "\n",
    "# SEM PESO\n",
    "classificador = KNeighborsClassifier(n_neighbors=7)\n",
    "classificador.fit(x_treino, y_treino)\n",
    "\n",
    "y_pred = classificador.predict(x_teste)\n",
    "\n",
    "print(classification_report(y_teste, y_pred))\n",
    "print(confusion_matrix(y_teste, y_pred))\n",
    "print(\"Porcentagem acertos: \", str(format(accuracy_score(y_teste, y_pred)*100, '.2f') + \"%\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISTANCIA EUCLIDIANA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.208325082500163\n"
     ]
    }
   ],
   "source": [
    "def calc_distancia(treino, teste):\n",
    "    # distância euclidiana\n",
    "    distancia = ((treino[0]-teste[0])**2 + (treino[1]-teste[1])**2 + (treino[2]-teste[2])**2 + (treino[3]-teste[3])**2)**0.5\n",
    "    return distancia\n",
    "\n",
    "treino = [5.1, 3.5, 1.4, 0.2]\n",
    "teste = [6.7, 3.1, 4.4, 1.4]\n",
    "\n",
    "print(calc_distancia(treino, teste))\n",
    "\n",
    "#TREINO\n",
    "#[5.1, 3.5, 1.4, 0.2]\n",
    "#[4.9, 3.0, 1.4, 0.2]\n",
    "#[6.9, 3.1, 4.9, 1.5]\n",
    "#[5.6, 3.0, 4.5, 1.5]\n",
    "#[6.8, 3.0, 5.5, 2.1]\n",
    "#[5.8, 2.7, 5.1, 1.9]\n",
    "\n",
    "#TESTE\n",
    "#[4.7, 3.2, 1.3, 0.2]\n",
    "#[7.2, 3.0, 5.8, 1.6]\n",
    "#[6.7, 3.1, 4.4, 1.4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
